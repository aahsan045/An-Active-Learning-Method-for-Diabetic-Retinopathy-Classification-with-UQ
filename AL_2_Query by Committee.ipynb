{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Active_Learning_Multi_MCDP_QBC_Final_Updated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U2hKURtMD5H"
      },
      "source": [
        "1. Load Bayesian CNN model as Annotator\n",
        "2. Active Learning will query the samples based on its acquistion function\n",
        "3. Queried samples will be sent to BCNN for labelling.\n",
        "4. Only those labels will be submitted whose labels are confidently returned by the BCNN model. \n",
        "5. Active Learning Model will be retrained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjE5z_wuFoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df01956c-9cae-4562-ff5e-a2d6069ab745"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDJpA6ywMwvS"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "tfkl=tfk.layers\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05zE3yFvuFGY"
      },
      "source": [
        "num_base_filters=32\n",
        "l2_reg=1e-4  #1e-4\n",
        "dropout_rate=0.15  # for MC-Dropout\n",
        "learning_rate=1e-4\n",
        "bs=64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9VPALIXuKB3"
      },
      "source": [
        "inputs=tfkl.Input((224,224,3))\n",
        "#Block1\n",
        "x=tfkl.Conv2D(filters=num_base_filters,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(inputs)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.MaxPooling2D(pool_size=3, strides=(2, 2), padding=\"same\")(x)\n",
        "#Block2\n",
        "x=tfkl.Conv2D(filters=num_base_filters*2,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*2,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.MaxPooling2D(pool_size=3, strides=(2, 2), padding=\"same\")(x)\n",
        "#Block3\n",
        "x=tfkl.Conv2D(filters=num_base_filters*4,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*4,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.MaxPooling2D(pool_size=3, strides=(2, 2), padding=\"same\")(x)\n",
        "# Block 4\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.MaxPooling2D(pool_size=5, strides=(3, 3), padding=\"same\")(x)\n",
        "# Block 5\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Conv2D(filters=num_base_filters*8,kernel_size=3,strides=(1, 1),padding=\"same\",kernel_regularizer=tfk.regularizers.l2(l2_reg))(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(dropout_rate)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.MaxPooling2D(pool_size=5, strides=(3, 3), padding=\"same\")(x)\n",
        "#x=tfkl.Lambda(lambda y: tfk.backend.concatenate([tfkl.GlobalAvgPool2D()(y),tfkl.GlobalMaxPool2D()(y)], axis=1))(x)\n",
        "x=tfkl.Flatten()(x)\n",
        "# Fully-connected\n",
        "x=tfkl.Dense(2048)(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(0.5)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Dense(512)(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(0.5)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "x=tfkl.Dense(128)(x)\n",
        "x=tfkl.LeakyReLU()(x)\n",
        "x=tfkl.Dropout(0.2)(x,training=True)\n",
        "x=tfkl.BatchNormalization()(x)\n",
        "outputs=tfkl.Dense(5,activation='softmax')(x)\n",
        "model=Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0HBaygmuZOr"
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/best_model_multi_class_ce.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUkqoS2ZFx00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c0a80b-bd8f-453a-faa4-49b78f17e187"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 224, 224, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 32)      9248      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 224, 224, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 64)      36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 13,057,317\n",
            "Trainable params: 13,047,973\n",
            "Non-trainable params: 9,344\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-KxhiS1oFd2"
      },
      "source": [
        "intermediate_model=Model(inputs=model.inputs,outputs=model.get_layer(\"leaky_re_lu_11\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc9ve5PXoLQZ"
      },
      "source": [
        "for layer in model.layers:\n",
        "  layer.trainable=False\n",
        "for layer in intermediate_model.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjHS_Vq3oOq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ba7ea4-26b4-4ad7-ef22-7adb5e07d5d2"
      },
      "source": [
        "print(intermediate_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 224, 224, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 32)      9248      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 224, 224, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 64)      36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 10, 10, 256)       0         \n",
            "=================================================================\n",
            "Total params: 3,539,488\n",
            "Trainable params: 0\n",
            "Non-trainable params: 3,539,488\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L20n1-27oO2G"
      },
      "source": [
        "X_O=[]\n",
        "y_O=[]\n",
        "X_F=[]\n",
        "y_F=[]\n",
        "import glob\n",
        "import cv2\n",
        "def make_arrays(dir):\n",
        "  for folders in dir:\n",
        "    for folder in folders:\n",
        "      label=int(folder[len(folder)-1])\n",
        "      #print(folder)\n",
        "      fldr= folder.split(\"/\")\n",
        "      fldr=fldr[len(fldr)-2]\n",
        "      if (fldr==\"test\" and label==0) or (fldr==\"test\" and label==1) or (fldr==\"test\" and label==2):\n",
        "        print(fldr)\n",
        "        print(label)\n",
        "        continue;\n",
        "      else:\n",
        "        files=glob.glob(folder + \"/*\")\n",
        "        #print(len(files))\n",
        "        for file in files:\n",
        "          res=cv2.cvtColor(cv2.resize(cv2.imread(file),(224,224)), cv2.COLOR_BGR2RGB)/255.0\n",
        "          X_O.append(res)\n",
        "          res=np.expand_dims(res,axis=0)\n",
        "          X_F.append(np.squeeze(intermediate_model(res,training=False),axis=0))\n",
        "          y_O.append(label)\n",
        "          y_F.append(label)\n",
        "  return np.array(X_O),np.array(y_O),np.array(X_F),np.array(y_F)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXzgPbc7oO95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7193a365-04dc-4654-cd93-59d590cfd3ca"
      },
      "source": [
        "filesv=glob.glob(\"/content/drive/My Drive/Multiclass Dataset New/val/*\")\n",
        "filest=glob.glob(\"/content/drive/My Drive/Multiclass Dataset New/test/*\")\n",
        "import tensorflow as tf\n",
        "X_O,y_O,X_F,y_F=make_arrays([filesv,filest])\n",
        "y_O=tf.keras.utils.to_categorical(y_O, num_classes=5, dtype='float32')\n",
        "y_F=tf.keras.utils.to_categorical(y_F, num_classes=5, dtype='float32')\n",
        "print(\"X Orig : \",X_O.shape)\n",
        "print(\"y Orig : \",y_O.shape)\n",
        "print(\"X Feat : \",X_F.shape)\n",
        "print(\"y_Feat : \",y_F.shape)\n",
        "# np.save(\"/content/X_F.npy\",X_F)\n",
        "# np.save(\"/content/y_F.npy\",y_F)\n",
        "# np.save(\"/content/X_O.npy\",X_O)\n",
        "# np.save(\"/content/y_O.npy\",y_O)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n",
            "0\n",
            "test\n",
            "1\n",
            "test\n",
            "2\n",
            "X Orig :  (2238, 224, 224, 3)\n",
            "y Orig :  (2238, 5)\n",
            "X Feat :  (2238, 10, 10, 256)\n",
            "y_Feat :  (2238, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFZ42pe3oPLW"
      },
      "source": [
        "p=np.random.permutation(range(0,len(X_F)))\n",
        "X_O=X_O[p]\n",
        "y_O=y_O[p]\n",
        "X_F=X_F[p]\n",
        "y_F=y_F[p]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI5hwdxqoPR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c60eba5-437d-435e-8e45-3899418d46e3"
      },
      "source": [
        "n_inctances=300\n",
        "train_idx = np.random.choice(range(X_F.shape[0]), size=n_inctances, replace=False)\n",
        "X_initial=X_F[train_idx]\n",
        "y_initial=y_F[train_idx]\n",
        "print(X_initial.shape)    \n",
        "print(y_initial.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 10, 10, 256)\n",
            "(300, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE-BKlLFBQDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e90f884-f689-4ea6-c5a9-e351a65e327c"
      },
      "source": [
        "n_initial=100\n",
        "p=np.random.choice(range(len(X_initial)),size=n_initial, replace=False)\n",
        "Xl1=X_initial[p]\n",
        "yl1=y_initial[p]\n",
        "X_initial = np.delete(X_initial, p, axis=0)\n",
        "y_initial = np.delete(y_initial, p, axis=0)\n",
        "print(Xl1.shape)\n",
        "print(yl1.shape)\n",
        "p=np.random.choice(range(len(X_initial)),size=n_initial, replace=False)\n",
        "Xl2=X_initial[p]\n",
        "yl2=y_initial[p]\n",
        "X_initial = np.delete(X_initial, p, axis=0)\n",
        "y_initial = np.delete(y_initial, p, axis=0)\n",
        "print(Xl2.shape)\n",
        "print(yl2.shape)\n",
        "p=np.random.choice(range(len(X_initial)),size=n_initial, replace=False)\n",
        "Xl3=X_initial[p]\n",
        "yl3=y_initial[p]\n",
        "X_initial = np.delete(X_initial, p, axis=0)\n",
        "y_initial = np.delete(y_initial, p, axis=0)\n",
        "print(Xl3.shape)\n",
        "print(yl3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 10, 10, 256)\n",
            "(100, 5)\n",
            "(100, 10, 10, 256)\n",
            "(100, 5)\n",
            "(100, 10, 10, 256)\n",
            "(100, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGf_Wf1KoPQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6c22c3-f4a0-4499-e9d5-e959e950ed46"
      },
      "source": [
        "X_O = np.delete(X_O, train_idx, axis=0)\n",
        "y_O = np.delete(y_O, train_idx, axis=0)\n",
        "X_F = np.delete(X_F, train_idx, axis=0)\n",
        "y_F = np.delete(y_F, train_idx, axis=0)\n",
        "print(X_O.shape)\n",
        "print(y_O.shape)\n",
        "print(X_F.shape)\n",
        "print(y_F.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1938, 224, 224, 3)\n",
            "(1938, 5)\n",
            "(1938, 10, 10, 256)\n",
            "(1938, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5QKxIqvoPO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585df93b-884d-43a6-f2fb-276a3b8dcedb"
      },
      "source": [
        "X_pool= X_F[0:int(0.70*X_F.shape[0])]\n",
        "X_orig= X_O[0:int(0.70*X_O.shape[0])]\n",
        "y_O = y_O[0:int(0.70*X_O.shape[0])]\n",
        "print(X_pool.shape)\n",
        "print(X_orig.shape)\n",
        "print(y_O.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1356, 10, 10, 256)\n",
            "(1356, 224, 224, 3)\n",
            "(1356, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20igKBEGoPJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f9ee75-1202-461c-80d0-e2ba0eda908d"
      },
      "source": [
        "X_test= X_F[int(0.70*X_F.shape[0]):]\n",
        "y_test = y_F[int(0.70*y_F.shape[0]):]\n",
        "print(X_test.shape)    \n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(582, 10, 10, 256)\n",
            "(582, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ETR54-toPHa"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=4.):\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvXN_AFzoPFl"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.models import Model\n",
        "opt=Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999)\n",
        "def create_keras_model():\n",
        "  inputs=tfkl.Input((10,10,256))\n",
        "  x=tfkl.Conv2D(256,3,strides=1,padding='valid',kernel_regularizer=tfk.regularizers.l2(1e-4))(inputs)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.20)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.MaxPool2D(pool_size=(2,2),strides=2)(x)\n",
        "  x=tfkl.Conv2D(256,3,strides=1,padding='same')(x)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.20)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.Conv2D(256,3,strides=1,padding='same')(x)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.20)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.Flatten()(x)\n",
        "  x=tfkl.Dense(2048,kernel_regularizer=tfk.regularizers.l2(1e-4))(x)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.25)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.Dense(512,kernel_regularizer=tfk.regularizers.l2(1e-4))(x)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.25)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.Dense(128,kernel_regularizer=tfk.regularizers.l2(1e-4))(x)\n",
        "  x=tfkl.LeakyReLU()(x)\n",
        "  x=tfkl.Dropout(0.25)(x,training=True)\n",
        "  x=tfkl.BatchNormalization()(x)\n",
        "  x=tfkl.Dense(5,kernel_regularizer=tfk.regularizers.l2(1e-4),activation='softmax')(x)\n",
        "  al_model=Model(inputs,x)\n",
        "  return al_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1d0kK8SoPCs"
      },
      "source": [
        "def Uncertainty_Quantification(x,model,num_samples):\n",
        "  mc_samples=np.array([model(x,training=True) for _ in range(num_samples)])\n",
        "  mc_samples=np.squeeze(mc_samples,axis=1)\n",
        "  mean_mc_samples=np.mean(mc_samples,axis=0)\n",
        "  y_pred=np.argmax(mean_mc_samples)\n",
        "  ent=-1*np.sum(np.multiply(mean_mc_samples,np.log(mean_mc_samples)),axis=0)\n",
        "  return ent,mean_mc_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s2ndAUJyf-5"
      },
      "source": [
        "classifier1 = create_keras_model()\n",
        "classifier1.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "classifier2 = create_keras_model()\n",
        "classifier2.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "classifier3 = create_keras_model()\n",
        "classifier3.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-VAZUBszlU9"
      },
      "source": [
        "classifier1.fit(Xl1,yl1,epochs=5,verbose=1,batch_size=4,shuffle=True)\n",
        "classifier2.fit(Xl2,yl2,epochs=5,verbose=1,batch_size=4,shuffle=True)\n",
        "classifier3.fit(Xl3,yl3,epochs=5,verbose=1,batch_size=4,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcAqlVRoO8c"
      },
      "source": [
        "def query(x,models,query_strategy=\"vote_entropy_sampling\"):\n",
        "  res=[]\n",
        "  for mod in models:\n",
        "    mc_samples=np.array([mod(x) for _ in range(25)])\n",
        "    mean_mc_samples=np.mean(mc_samples,axis=0)\n",
        "    res.append(mean_mc_samples)\n",
        "  res=np.array(res)\n",
        "  pred=np.argmax(res,axis=2)\n",
        "  count = (np.arange(res.shape[2])==pred[...,np.newaxis]).sum(axis=0) # np.arang(No_of_classes)....\n",
        "  vote_p = count/len(models) \n",
        "  vote_p=vote_p + 1e-8\n",
        "  ent= -(vote_p*np.log(vote_p)).sum(axis=1)\n",
        "  query_index=np.argmax(ent)\n",
        "  return query_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPgsVRZfplU9"
      },
      "source": [
        "models=[classifier1,classifier2,classifier3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huh12KqCz-hF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185796bc-18fa-4060-f9f9-47397350ea10"
      },
      "source": [
        "print(classifier1.evaluate(X_test,y_test,verbose=0)[1]*100)\n",
        "print(classifier2.evaluate(X_test,y_test,verbose=0)[1]*100)\n",
        "print(classifier3.evaluate(X_test,y_test,verbose=0)[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57.21649527549744\n",
            "57.731956243515015\n",
            "55.498284101486206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWEATqNZGLAw"
      },
      "source": [
        "def evaluate(models,x,y):\n",
        "  y_pred=[]\n",
        "  count=0;\n",
        "  for mod in models:\n",
        "    p_samples=np.array(mod(x,training=True))\n",
        "    y_pred.append(p_samples)\n",
        "  y_pred=np.array(y_pred)\n",
        "  y_pred=np.mean(y_pred,axis=0)\n",
        "  y_pred=np.argmax(y_pred,axis=1)\n",
        "  y_true=np.argmax(y,axis=1)\n",
        "  for i in range(y_pred.shape[0]):\n",
        "    if y_pred[i]==y_true[i]:\n",
        "      count+=1\n",
        "  return count/y_pred.shape[0]*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSPvAR6zq4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f91965-6427-4855-b6cc-0dc55f4bc8e8"
      },
      "source": [
        "N_QUERIES = 1200\n",
        "scor=[]\n",
        "xtr=[]\n",
        "ytr=[]\n",
        "index=0\n",
        "while (index < N_QUERIES):\n",
        "  index+=1\n",
        "  p=np.random.permutation(range(X_pool.shape[0]))\n",
        "  X_pool=X_pool[p]\n",
        "  X_orig=X_orig[p]\n",
        "  y_O=y_O[p]\n",
        "  pool_f=X_pool[0:10]\n",
        "  pool_o=X_orig[0:10]\n",
        "  pool_y= y_O[0:10]\n",
        "  models=[classifier1,classifier2,classifier3]\n",
        "  query_index=query(pool_f,models,query_strategy=\"uncertainty_sampling\")\n",
        "  x=np.expand_dims(pool_o[query_index],axis=0)\n",
        "  # print(x.shape)\n",
        "  ent,mean_mc_prob=Uncertainty_Quantification(x,model,10)\n",
        "  y_pred=tf.keras.utils.to_categorical(np.argmax(mean_mc_prob), num_classes=5, dtype='float32')\n",
        "  if ent < 1.276:\n",
        "    xtr.append(pool_f[query_index])\n",
        "    ytr.append(y_O[query_index])\n",
        "  if index % 16 == 0:\n",
        "    xtr=np.array(xtr)\n",
        "    ytr=np.array(ytr)\n",
        "    bs=16;\n",
        "    Xl1=np.concatenate((xtr,Xl1),axis=0)\n",
        "    yl1=np.concatenate((ytr,yl1),axis=0)\n",
        "    Xl2=np.concatenate((xtr,Xl2),axis=0)\n",
        "    yl2=np.concatenate((ytr,yl2),axis=0)\n",
        "    Xl3=np.concatenate((xtr,Xl3),axis=0)\n",
        "    yl3=np.concatenate((ytr,yl3),axis=0)\n",
        "    print(\"New Training Size after Query No. :\",index,Xl1.shape[0])\n",
        "    classifier1.fit(Xl1,yl1,epochs=20,verbose=0,batch_size=bs,shuffle=True)\n",
        "    classifier2.fit(Xl2,yl2,epochs=20,verbose=0,batch_size=bs,shuffle=True)\n",
        "    classifier3.fit(Xl3,yl3,epochs=20,verbose=0,batch_size=bs,shuffle=True)\n",
        "    scr=evaluate(models,X_test,y_test)\n",
        "    scor.append(scr)\n",
        "    print(\"Test Accuracy after Iteration:\",index,scr)\n",
        "    xtr=[]\n",
        "    ytr=[]\n",
        "  X_pool = np.delete(X_pool, query_index, axis=0)\n",
        "  X_orig= np.delete(X_orig, query_index, axis=0)\n",
        "  y_O= np.delete(y_O, query_index, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New Training Size after Query No. : 16 116\n",
            "Test Accuracy after Iteration: 16 69.24398625429554\n",
            "New Training Size after Query No. : 32 132\n",
            "Test Accuracy after Iteration: 32 70.44673539518901\n",
            "New Training Size after Query No. : 48 148\n",
            "Test Accuracy after Iteration: 48 73.02405498281786\n",
            "New Training Size after Query No. : 64 164\n",
            "Test Accuracy after Iteration: 64 74.91408934707904\n",
            "New Training Size after Query No. : 80 180\n",
            "Test Accuracy after Iteration: 80 75.94501718213058\n",
            "New Training Size after Query No. : 96 196\n",
            "Test Accuracy after Iteration: 96 75.08591065292096\n",
            "New Training Size after Query No. : 112 212\n",
            "Test Accuracy after Iteration: 112 74.74226804123711\n",
            "New Training Size after Query No. : 128 228\n",
            "Test Accuracy after Iteration: 128 76.97594501718214\n",
            "New Training Size after Query No. : 144 244\n",
            "Test Accuracy after Iteration: 144 75.4295532646048\n",
            "New Training Size after Query No. : 160 260\n",
            "Test Accuracy after Iteration: 160 76.80412371134021\n",
            "New Training Size after Query No. : 176 276\n",
            "Test Accuracy after Iteration: 176 77.14776632302406\n",
            "New Training Size after Query No. : 192 292\n",
            "Test Accuracy after Iteration: 192 79.20962199312714\n",
            "New Training Size after Query No. : 208 307\n",
            "Test Accuracy after Iteration: 208 76.46048109965635\n",
            "New Training Size after Query No. : 224 323\n",
            "Test Accuracy after Iteration: 224 78.00687285223368\n",
            "New Training Size after Query No. : 240 339\n",
            "Test Accuracy after Iteration: 240 77.4914089347079\n",
            "New Training Size after Query No. : 256 355\n",
            "Test Accuracy after Iteration: 256 77.83505154639175\n",
            "New Training Size after Query No. : 272 371\n",
            "Test Accuracy after Iteration: 272 79.38144329896907\n",
            "New Training Size after Query No. : 288 387\n",
            "Test Accuracy after Iteration: 288 79.89690721649485\n",
            "New Training Size after Query No. : 304 403\n",
            "Test Accuracy after Iteration: 304 80.58419243986255\n",
            "New Training Size after Query No. : 320 419\n",
            "Test Accuracy after Iteration: 320 80.75601374570446\n",
            "New Training Size after Query No. : 336 435\n",
            "Test Accuracy after Iteration: 336 80.41237113402062\n",
            "New Training Size after Query No. : 352 451\n",
            "Test Accuracy after Iteration: 352 81.61512027491409\n",
            "New Training Size after Query No. : 368 467\n",
            "Test Accuracy after Iteration: 368 78.1786941580756\n",
            "New Training Size after Query No. : 384 483\n",
            "Test Accuracy after Iteration: 384 81.09965635738831\n",
            "New Training Size after Query No. : 400 499\n",
            "Test Accuracy after Iteration: 400 80.06872852233677\n",
            "New Training Size after Query No. : 416 515\n",
            "Test Accuracy after Iteration: 416 80.9278350515464\n",
            "New Training Size after Query No. : 432 531\n",
            "Test Accuracy after Iteration: 432 83.33333333333334\n",
            "New Training Size after Query No. : 448 547\n",
            "Test Accuracy after Iteration: 448 82.13058419243985\n",
            "New Training Size after Query No. : 464 563\n",
            "Test Accuracy after Iteration: 464 81.44329896907216\n",
            "New Training Size after Query No. : 480 579\n",
            "Test Accuracy after Iteration: 480 81.61512027491409\n",
            "New Training Size after Query No. : 496 595\n",
            "Test Accuracy after Iteration: 496 82.64604810996563\n",
            "New Training Size after Query No. : 512 611\n",
            "Test Accuracy after Iteration: 512 81.61512027491409\n",
            "New Training Size after Query No. : 528 627\n",
            "Test Accuracy after Iteration: 528 82.9896907216495\n",
            "New Training Size after Query No. : 544 643\n",
            "Test Accuracy after Iteration: 544 83.8487972508591\n",
            "New Training Size after Query No. : 560 659\n",
            "Test Accuracy after Iteration: 560 82.9896907216495\n",
            "New Training Size after Query No. : 576 675\n",
            "Test Accuracy after Iteration: 576 84.36426116838489\n",
            "New Training Size after Query No. : 592 691\n",
            "Test Accuracy after Iteration: 592 83.8487972508591\n",
            "New Training Size after Query No. : 608 707\n",
            "Test Accuracy after Iteration: 608 85.39518900343643\n",
            "New Training Size after Query No. : 624 723\n",
            "New Training Size after Query No. : 640 739\n",
            "Test Accuracy after Iteration: 640 85.91065292096219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qchloKaYeTd1"
      },
      "source": [
        "import numpy as np\n",
        "np.save(\"/content/Final_Accu_AL_MCDP_Multi_QBC_ce.npy\",scor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI28CNMIRNXS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(scor)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}